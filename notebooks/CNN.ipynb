{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_Forgery_Predictor_Model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(2, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JPEGCompression(image, quality):\n",
    "    # Simulación de compresión JPEG, puedes utilizar librerías como PIL para una compresión real\n",
    "    return tf.image.adjust_jpeg_quality(image, jpeg_quality=quality)\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image_resized = tf.image.resize(image, (128, 128))\n",
    "    image_compressed = JPEGCompression(image_resized, quality=75)\n",
    "    image_diff = tf.subtract(image_resized, image_compressed)\n",
    "    return image_diff.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(images, labels, epochs=10):\n",
    "    model = Image_Forgery_Predictor_Model()\n",
    "    training_data = []\n",
    "    for image in images:\n",
    "        diff_image = preprocess_image(image)\n",
    "        training_data.append(diff_image)\n",
    "    training_data = np.array(training_data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Dividir los datos en conjuntos de entrenamiento y validación\n",
    "    X_train, X_val, y_train, y_val = train_test_split(training_data, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Convertir las etiquetas a una representación binaria\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, num_classes=2)\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, input_image):\n",
    "    input_diff_image = preprocess_image(input_image)\n",
    "    input_diff_image = np.expand_dims(input_diff_image, axis=0)  # Añadir dimensión de lote\n",
    "    predicted_label = model.predict(input_diff_image)\n",
    "    if predicted_label[0][0] > predicted_label[0][1]:\n",
    "        return \"Tampered\"\n",
    "    else:\n",
    "        return \"Untampered\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your CASIA2 dataset\n",
    "PATH = '../data/CASIA2'\n",
    "\n",
    "# Directories for authentic and tampered images\n",
    "authentic_dir = os.path.join(PATH, 'Au')\n",
    "tampered_dir = os.path.join(PATH, 'Tp')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (160, 160)\n",
    "\n",
    "def get_file_list_and_labels(directory, label):\n",
    "    file_list = []\n",
    "    labels = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                file_list.append(os.path.join(root, file))\n",
    "                labels.append(label)\n",
    "    return file_list, labels\n",
    "\n",
    "# Get file lists and labels\n",
    "authentic_files, authentic_labels = get_file_list_and_labels(authentic_dir, 0)\n",
    "tampered_files, tampered_labels = get_file_list_and_labels(tampered_dir, 1)\n",
    "\n",
    "# Combine authentic and tampered data\n",
    "all_files = authentic_files + tampered_files\n",
    "all_labels = authentic_labels + tampered_labels\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(\n",
    "    all_files, all_labels, test_size=0.2, random_state=42, stratify=all_labels\n",
    ")\n",
    "\n",
    "def create_dataset(file_list, labels):\n",
    "    labels = np.array(labels)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((file_list, labels))\n",
    "    ds = ds.map(lambda x, y: (tf.io.read_file(x), y))\n",
    "    ds = ds.map(lambda x, y: (tf.image.decode_jpeg(x, channels=3), y))\n",
    "    ds = ds.map(lambda x, y: (tf.image.resize(x, IMG_SIZE), y))\n",
    "    return ds.shuffle(1000).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_dataset = create_dataset(train_files, train_labels)\n",
    "validation_dataset = create_dataset(val_files, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m directory_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/CASIA2/Tp\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Cargar las imágenes\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m images \u001b[38;5;241m=\u001b[39m load_images_from_directory(directory_path)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Imprimir la cantidad de imágenes cargadas\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSe han cargado \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(images)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m imágenes.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[22], line 14\u001b[0m, in \u001b[0;36mload_images_from_directory\u001b[1;34m(directory_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tiff\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     13\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory_path, filename)\n\u001b[1;32m---> 14\u001b[0m     image_tensor \u001b[38;5;241m=\u001b[39m load_tif_image(image_path)\n\u001b[0;32m     15\u001b[0m     resized \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mresize(image_tensor, IMG_SIZE)\n\u001b[0;32m     16\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(image_tensor)\n",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m, in \u001b[0;36mload_tif_image\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_tif_image\u001b[39m(file_path):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Cargar la imagen usando Pillow\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(file_path)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Convertir la imagen a un arreglo numpy\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     image_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "def load_tif_image(file_path):\n",
    "    # Cargar la imagen usando Pillow\n",
    "    image = Image.open(file_path)\n",
    "    # Convertir la imagen a un arreglo numpy\n",
    "    image_array = np.array(image)\n",
    "    # Convertir el arreglo numpy a un tensor de TensorFlow\n",
    "    return tf.convert_to_tensor(image_array)\n",
    "\n",
    "def load_images_from_directory(directory_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".tif\") or filename.endswith(\".tiff\"):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            image_tensor = load_tif_image(image_path)\n",
    "            resized = tf.image.resize(image_tensor, IMG_SIZE)\n",
    "            images.append(image_tensor)\n",
    "        elif filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            image_tensor = tf.io.read_file(image_path)\n",
    "            image_tensor = tf.image.decode_image(image_tensor)\n",
    "            images.append(image_tensor)\n",
    "    return images\n",
    "\n",
    "# Directorio donde se encuentran las imágenes\n",
    "directory_path = '../data/CASIA2/Tp'\n",
    "\n",
    "# Cargar las imágenes\n",
    "images = load_images_from_directory(directory_path)\n",
    "\n",
    "# Imprimir la cantidad de imágenes cargadas\n",
    "print(f'Se han cargado {len(images)} imágenes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Supongamos que tenemos un conjunto de imágenes `images` y sus etiquetas `labels`\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# images = [...]  # Lista de imágenes (numpy arrays)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# labels = [...]  # Lista de etiquetas correspondientes (0 para no manipuladas, 1 para manipuladas)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m train_model(images, labels, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Predicción de una imagen de entrada\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# input_image = [...]  # Una imagen de entrada (numpy array)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m result \u001b[38;5;241m=\u001b[39m predict_image(model, input_image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "# Supongamos que tenemos un conjunto de imágenes `images` y sus etiquetas `labels`\n",
    "# images = [...]  # Lista de imágenes (numpy arrays)\n",
    "# labels = [...]  # Lista de etiquetas correspondientes (0 para no manipuladas, 1 para manipuladas)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = train_model(images, labels, epochs=10)\n",
    "\n",
    "# Predicción de una imagen de entrada\n",
    "# input_image = [...]  # Una imagen de entrada (numpy array)\n",
    "result = predict_image(model, input_image)\n",
    "print(\"Resultado de la predicción:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
