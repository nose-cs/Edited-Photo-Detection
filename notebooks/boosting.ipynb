{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import prepare_image_forgery_dataset\n",
    "import os\n",
    "\n",
    "PATH = '../data/CASIA2'\n",
    "authentic_dir = os.path.join(PATH, 'Au')\n",
    "tampered_dir = os.path.join(PATH, 'Tp2')\n",
    "\n",
    "authentic_number = 100\n",
    "tampered_number = 100\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_image_forgery_dataset(authentic_dir, tampered_dir,\n",
    "                                                                 authentic_number=authentic_number,\n",
    "                                                                 tampered_number=tampered_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomBoostingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Custom Boosting Classifier for ensemble learning.\n",
    "\n",
    "    This classifier implements a custom boosting algorithm similar to AdaBoost.\n",
    "    It combines multiple base models to create a strong ensemble classifier.\n",
    "\n",
    "    Key features:\n",
    "    - Flexible base model selection: Uses a list of provided base models.\n",
    "    - Iterative learning: Improves prediction by focusing on misclassified samples.\n",
    "    - Weighted voting: Final prediction is based on weighted votes of base models.\n",
    "    - Validation error tracking: Monitors performance on a validation set.\n",
    "\n",
    "    The algorithm works by:\n",
    "    1. Iteratively training base models on weighted training data.\n",
    "    2. Selecting the best performing model in each iteration.\n",
    "    3. Updating sample weights to focus on misclassified samples.\n",
    "    4. Combining model predictions using learned weights.\n",
    "\n",
    "    This classifier is compatible with scikit-learn's API, inheriting from\n",
    "    BaseEstimator and ClassifierMixin.\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, base_models, n_estimators=10, learning_rate=0.1, validation_fraction=0.1, random_state=42):\n",
    "        \"\"\"\n",
    "        Initialize the CustomBoostingClassifier.\n",
    "\n",
    "        :param base_models: List of base model instances to be used in boosting\n",
    "        :param n_estimators: Number of boosting iterations\n",
    "        :param learning_rate: Step size shrinkage used in update to prevents overfitting\n",
    "        :param validation_fraction: Proportion of training data to set aside as validation set\n",
    "        :param random_state: Seed for random number generation\n",
    "        \"\"\"\n",
    "        self.base_models = base_models\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.validation_fraction = validation_fraction\n",
    "        self.random_state = random_state\n",
    "        self.models = []  # List to store selected models\n",
    "        self.weights = []  # List to store model weights\n",
    "        self.validation_errors = []  # List to store validation errors\n",
    "\n",
    "    def print_history(self):\n",
    "        \"\"\"\n",
    "        Print the history for each boosting iteration.\n",
    "        \"\"\"\n",
    "        print(\"=\"*50)\n",
    "        print(\"Validation Error History:\")\n",
    "        for i, error in enumerate(self.validation_errors, 1):\n",
    "            print(f\"{i}: {error:.4f}\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Best Model History:\")\n",
    "        for i, model in enumerate(self.models, 1):\n",
    "            print(f\"{i}: {model.__class__.__name__}\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the boosting classifier on the training data.\n",
    "\n",
    "        :param X: Training data features\n",
    "        :param y: Training data labels\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        # Split data into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=self.validation_fraction, random_state=self.random_state)\n",
    "        \n",
    "        self.classes_ = np.unique(y_train)\n",
    "        n_samples = X_train.shape[0]\n",
    "        sample_weights = np.ones(n_samples) / n_samples  # Initialize sample weights\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            best_model = None\n",
    "            best_error = float('inf')\n",
    "            \n",
    "            # Find the best model for current weighted samples\n",
    "            for model in self.base_models:\n",
    "                model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "                predictions = model.predict(X_train)\n",
    "                error = np.sum(sample_weights * (predictions != y_train)) / np.sum(sample_weights)\n",
    "                \n",
    "                if error < best_error:\n",
    "                    best_model = model\n",
    "                    best_error = error\n",
    "\n",
    "            # Calculate model weight\n",
    "            model_weight = self.learning_rate * np.log((1 - best_error) / best_error)\n",
    "            \n",
    "            # Update sample weights\n",
    "            predictions = best_model.predict(X_train)\n",
    "            sample_weights *= np.exp(model_weight * (predictions != y_train))\n",
    "            sample_weights /= np.sum(sample_weights)  # Normalize weights\n",
    "\n",
    "            # Store the best model and its weight\n",
    "            self.models.append(best_model)\n",
    "            self.weights.append(model_weight)\n",
    "\n",
    "            # Evaluate on validation set\n",
    "            val_pred = self.predict(X_val)\n",
    "            val_error = np.mean(val_pred != y_val)\n",
    "            self.validation_errors.append(val_error) \n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels for samples in X.\n",
    "\n",
    "        :param X: The input samples\n",
    "        :return: Predicted class labels\n",
    "        \"\"\"\n",
    "        predictions = np.zeros((len(self.models), X.shape[0]))\n",
    "        for i, model in enumerate(self.models):\n",
    "            predictions[i] = model.predict(X)\n",
    "            # Uncomment below line if working with probabilities\n",
    "            # predictions[i] = (predictions[i].ravel() > 0.5).astype(int)  # Convert probabilities to labels\n",
    "\n",
    "        # Compute weighted sum of predictions\n",
    "        weighted_preds = np.sum(np.array(self.weights)[:, np.newaxis] * predictions, axis=0)\n",
    "        \n",
    "        # Convert to class labels\n",
    "        return self.classes_[(weighted_preds > 0).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from models.cnn import CNNImageForgeryDetector\n",
    "from models.svm import SVMImageForgeryDetector\n",
    "from models.fine_tuning import TransferLearningImageForgeryDetector\n",
    "\n",
    "base_models = [TransferLearningImageForgeryDetector() for _ in range(1)] + \\\n",
    "              [SVMImageForgeryDetector(use_edges=False, use_noise=False, use_texture=False) for _ in range(1)] + \\\n",
    "              [CNNImageForgeryDetector() for _ in range(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_model = CustomBoostingClassifier(base_models, n_estimators=1, learning_rate=0.1)\n",
    "boosting_model.fit(X_train, y_train)\n",
    "boosting_model.print_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = boosting_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anabelbg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
