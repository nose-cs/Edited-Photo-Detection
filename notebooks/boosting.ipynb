{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 00:50:36.470022: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-07 00:50:36.470437: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-07 00:50:36.592809: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-07 00:50:36.848621: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-07 00:50:39.832978: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from utils import prepare_image_forgery_dataset\n",
    "import os\n",
    "\n",
    "PATH = '../data/CASIA2'\n",
    "authentic_dir = os.path.join(PATH, 'Au')\n",
    "tampered_dir = os.path.join(PATH, 'Tp2')\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_image_forgery_dataset(authentic_dir, tampered_dir, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class SimpleBoostingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_models, rounds=5, learning_rate=0.1, validation_fraction=0.1, random_state=42):\n",
    "        self.base_models = base_models\n",
    "        self.rounds = rounds\n",
    "        self.learning_rate = learning_rate\n",
    "        self.validation_fraction = validation_fraction\n",
    "        self.random_state = random_state\n",
    "        self.models = []\n",
    "        self.alphas = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Asegurarse de que y sea un array 1D\n",
    "        y = np.ravel(y)\n",
    "\n",
    "        # Dividir los datos en conjuntos de entrenamiento y validación\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=self.validation_fraction, random_state=self.random_state)\n",
    "\n",
    "        self.classes_ = np.unique(y_train)\n",
    "\n",
    "        # Inicializar pesos\n",
    "        weights = np.ones(len(y_train)) / len(y_train)\n",
    "\n",
    "        for i in range(self.rounds):\n",
    "            errors = np.zeros(len(self.base_models))\n",
    "            predictions = np.zeros((len(self.base_models), len(y_train)))\n",
    "\n",
    "            # Entrenar modelos base y calcular errores\n",
    "            for i, model in enumerate(self.base_models):\n",
    "                model.fit(X_train, y_train, sample_weight=weights)\n",
    "                pred = model.predict(X_train)\n",
    "                predictions[i] = (pred.ravel() > 0.5).astype(int)  # Convertir probabilidades a etiquetas\n",
    "                errors[i] = np.sum(weights * (predictions[i] != y_train.astype(int)))\n",
    "\n",
    "            # Seleccionar el mejor modelo\n",
    "            best_model_index = np.argmin(errors)\n",
    "            best_model = self.base_models[best_model_index]\n",
    "            best_pred = predictions[best_model_index]\n",
    "\n",
    "            # Calcular alpha\n",
    "            error = errors[best_model_index]\n",
    "            alpha = self.learning_rate * (np.log((1 - error) / error) + np.log(len(self.classes_) - 1))\n",
    "\n",
    "            # Actualizar pesos\n",
    "            weights *= np.exp(alpha * (best_pred != y_train.astype(int)))\n",
    "            weights /= np.sum(weights)\n",
    "\n",
    "            # Guardar modelo y alpha\n",
    "            self.models.append(best_model)\n",
    "            self.alphas.append(alpha)\n",
    "\n",
    "            # Evaluar en el conjunto de validación\n",
    "            val_pred = self.predict(X_val)\n",
    "            val_error = np.mean(val_pred != y_val.astype(int))\n",
    "            print(f\"Validation error after round {i} model {len(self.models)}: {val_error:.4f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros((len(self.models), X.shape[0]))\n",
    "        for i, model in enumerate(self.models):\n",
    "            pred = model.predict(X)\n",
    "            predictions[i] = (pred.ravel() > 0.5).astype(int)  # Convertir probabilidades a etiquetas\n",
    "\n",
    "        weighted_preds = np.sum(np.array(self.alphas)[:, np.newaxis] * predictions, axis=0)\n",
    "\n",
    "        return self.classes_[(weighted_preds > 0).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 8s 255ms/step - loss: 0.0051 - accuracy: 0.5694\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 233ms/step - loss: 0.0053 - accuracy: 0.5903\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.0051 - accuracy: 0.5556\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.0053 - accuracy: 0.5278\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.0053 - accuracy: 0.5486\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.0052 - accuracy: 0.5694\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.0054 - accuracy: 0.5486\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 1s 267ms/step - loss: 0.0048 - accuracy: 0.6250\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 1s 273ms/step - loss: 0.0053 - accuracy: 0.5903\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.0053 - accuracy: 0.5069\n",
      "Epoch 10/20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from models.cnn import CNNImageForgeryPredictorModel\n",
    "from models.svm import SVMImageForgeryPredictorModel\n",
    "from models.fine_tuning import TransferLearningImageForgeryPredictorModel\n",
    "\n",
    "base_models = [TransferLearningImageForgeryPredictorModel() for _ in range(2)] + \\\n",
    "            [SVMImageForgeryPredictorModel() for _ in range(2)] + \\\n",
    "            [CNNImageForgeryPredictorModel() for _ in range(2)]\n",
    "\n",
    "# Crear y entrenar el modelo de boosting con early stopping\n",
    "boosting_model = SimpleBoostingClassifier(base_models, rounds=1)\n",
    "boosting_model.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones y evaluar\n",
    "y_pred = boosting_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomBoostingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_models, n_estimators=10, learning_rate=0.1, validation_fraction=0.1, random_state=42):\n",
    "        self.base_models = base_models\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.validation_fraction = validation_fraction\n",
    "        self.random_state = random_state\n",
    "        self.models = []\n",
    "        self.weights = []\n",
    "        self.validation_errors = []  # Nueva lista para almacenar los errores de validación\n",
    "\n",
    "    def print_validation_history(self):\n",
    "        print(\"Validation Error History:\")\n",
    "        for i, error in enumerate(self.validation_errors, 1):\n",
    "            print(f\"Model {i}: {error:.4f}\")\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=self.validation_fraction, random_state=self.random_state)\n",
    "        \n",
    "        self.classes_ = np.unique(y_train)\n",
    "        n_samples = X_train.shape[0]\n",
    "        sample_weights = np.ones(n_samples) / n_samples\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            best_model = None\n",
    "            best_error = float('inf')\n",
    "            \n",
    "            for model in self.base_models:\n",
    "                model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "                predictions = model.predict(X_train)\n",
    "                error = np.sum(sample_weights * (predictions != y_train)) / np.sum(sample_weights)\n",
    "                \n",
    "                if error < best_error:\n",
    "                    best_model = model\n",
    "                    best_error = error\n",
    "\n",
    "            # Calcular el peso del modelo\n",
    "            model_weight = self.learning_rate * np.log((1 - best_error) / best_error)\n",
    "            \n",
    "            # Actualizar los pesos de las muestras\n",
    "            predictions = best_model.predict(X_train)\n",
    "            sample_weights *= np.exp(model_weight * (predictions != y_train))\n",
    "            sample_weights /= np.sum(sample_weights)\n",
    "\n",
    "            self.models.append(best_model)\n",
    "            self.weights.append(model_weight)\n",
    "\n",
    "            # Evaluar en el conjunto de validación\n",
    "            val_pred = self.predict(X_val)\n",
    "            val_error = np.mean(val_pred != y_val)\n",
    "            self.validation_errors.append(val_error) \n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros((len(self.models), X.shape[0]))\n",
    "        for i, model in enumerate(self.models):\n",
    "            predictions[i] = model.predict(X)\n",
    "\n",
    "        weighted_preds = np.sum(np.array(self.weights)[:, np.newaxis] * predictions, axis=0)\n",
    "        return self.classes_[(weighted_preds > 0).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [TransferLearningImageForgeryPredictorModel() for _ in range(2)] + \\\n",
    "              [SVMImageForgeryPredictorModel() for _ in range(2)] + \\\n",
    "              [CNNImageForgeryPredictorModel() for _ in range(2)]\n",
    "\n",
    "boosting_model = CustomBoostingClassifier(base_models, n_estimators=10, learning_rate=0.1)\n",
    "boosting_model.fit(X_train, y_train)\n",
    "boosting_model.print_validation_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = boosting_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anabelbg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
