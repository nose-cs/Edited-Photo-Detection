{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "class SimpleBoostingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_models, num_rounds=50, learning_rate=0.1):\n",
    "        self.base_models = base_models\n",
    "        self.num_rounds = num_rounds\n",
    "        self.learning_rate = learning_rate\n",
    "        self.models = []\n",
    "        self.alphas = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        # Inicializar pesos\n",
    "        weights = np.ones(len(y)) / len(y)\n",
    "        \n",
    "        for _ in range(self.num_rounds):\n",
    "            errors = np.zeros(len(self.base_models))\n",
    "            predictions = np.zeros((len(self.base_models), len(y)))\n",
    "            \n",
    "            # Entrenar modelos base y calcular errores\n",
    "            for i, model in enumerate(self.base_models):\n",
    "                model.fit(X, y, sample_weight=weights)\n",
    "                predictions[i] = model.predict(X)\n",
    "                errors[i] = np.sum(weights * (predictions[i] != y))\n",
    "            \n",
    "            # Seleccionar el mejor modelo\n",
    "            best_model_index = np.argmin(errors)\n",
    "            best_model = self.base_models[best_model_index]\n",
    "            best_pred = predictions[best_model_index]\n",
    "            \n",
    "            # Calcular alpha\n",
    "            error = errors[best_model_index]\n",
    "            alpha = self.learning_rate * (np.log((1 - error) / error) + np.log(len(self.classes_) - 1))\n",
    "            \n",
    "            # Actualizar pesos\n",
    "            weights *= np.exp(alpha * (best_pred != y))\n",
    "            weights /= np.sum(weights)\n",
    "            \n",
    "            # Guardar modelo y alpha\n",
    "            self.models.append(best_model)\n",
    "            self.alphas.append(alpha)\n",
    "        \n",
    "        # Convertir alphas a un array de numpy\n",
    "        self.alphas = np.array(self.alphas)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        \n",
    "        predictions = np.zeros((len(self.models), X.shape[0]))\n",
    "        for i, model in enumerate(self.models):\n",
    "            predictions[i] = model.predict(X)\n",
    "        \n",
    "        weighted_preds = np.sum(self.alphas[:, np.newaxis] * predictions, axis=0)\n",
    "        \n",
    "        # Si solo hay dos clases, usamos un umbral de 0\n",
    "        if len(self.classes_) == 2:\n",
    "            return self.classes_[(weighted_preds > 0).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "# Crear datos de ejemplo\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Definir los números de rondas a probar\n",
    "round_numbers = [10, 50, 100, 200, 500]\n",
    "\n",
    "# Almacenar los resultados\n",
    "mean_scores = []\n",
    "\n",
    "for num_rounds in round_numbers:\n",
    "    # Crear modelos base\n",
    "    base_models = [DecisionTreeClassifier(max_depth=1) for _ in range(10)]\n",
    "    \n",
    "    # Crear el modelo de boosting\n",
    "    boosting_model = SimpleBoostingClassifier(base_models, num_rounds=num_rounds, learning_rate=0.1)\n",
    "    \n",
    "    # Realizar validación cruzada\n",
    "    scores = cross_val_score(boosting_model, X, y, cv=5)\n",
    "    \n",
    "    # Almacenar la puntuación media\n",
    "    mean_scores.append(np.mean(scores))\n",
    "\n",
    "# Encontrar el mejor número de rondas\n",
    "best_rounds = round_numbers[np.argmax(mean_scores)]\n",
    "\n",
    "print(\"Resultados:\")\n",
    "for rounds, score in zip(round_numbers, mean_scores):\n",
    "    print(f\"Rondas: {rounds}, Puntuación media: {score:.4f}\")\n",
    "print(f\"\\nMejor número de rondas: {best_rounds}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anabelbg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
