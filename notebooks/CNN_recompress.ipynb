{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 20:31:21.479461: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-04 20:31:21.620104: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-04 20:31:21.795867: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-04 20:31:21.967470: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-04 20:31:21.968860: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-04 20:31:22.230794: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-04 20:31:24.332379: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_Forgery_Predictor_Model():\n",
    "    model = Sequential([\n",
    "        Input(shape=(128, 128, 3)),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(2, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomprimir_imagen_tf(imagen, calidad=50):\n",
    "    imagen_jpeg = tf.image.encode_jpeg(imagen, quality=calidad)\n",
    "    imagen_recomprimida = tf.image.decode_jpeg(imagen_jpeg)\n",
    "    return imagen_recomprimida\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image_compressed = recomprimir_imagen_tf(image, calidad=50)\n",
    "    diff = tf.abs(tf.cast(image, tf.int32) - tf.cast(image_compressed, tf.int32))\n",
    "    resized = tf.image.resize(diff, (128, 128))\n",
    "    return resized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(images, labels, epochs=10):\n",
    "    model = Image_Forgery_Predictor_Model()\n",
    "    training_data = []\n",
    "    for image in images:\n",
    "        diff_image = preprocess_image(image)\n",
    "        training_data.append(diff_image)\n",
    "    training_data = np.array(training_data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Dividir los datos en conjuntos de entrenamiento y validación\n",
    "    X_train, X_val, y_train, y_val = train_test_split(training_data, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Convertir las etiquetas a una representación binaria\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, num_classes=2)\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your CASIA2 dataset\n",
    "PATH = '../data/CASIA2'\n",
    "\n",
    "# Directories for authentic and tampered images\n",
    "authentic_dir = os.path.join(PATH, 'Au')\n",
    "tampered_dir = os.path.join(PATH, 'Tp2')\n",
    "\n",
    "authentic_number = 100\n",
    "tampered_number = 100\n",
    "\n",
    "def load_images_from_directory(directory_path, n, i=0):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory_path)[i:n]:\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            imagen_original = tf.io.read_file(image_path)\n",
    "            imagen_original = tf.image.decode_jpeg(imagen_original, channels=3)\n",
    "            diff_image = preprocess_image(imagen_original)\n",
    "            images.append(diff_image)\n",
    "    return images\n",
    "\n",
    "# Get file lists and labels\n",
    "authentic_files = load_images_from_directory(authentic_dir, authentic_number)\n",
    "tampered_files = load_images_from_directory(tampered_dir, tampered_number)\n",
    "authentic_labels = [0] * len(authentic_files)\n",
    "tampered_labels = [0] * len(tampered_files)\n",
    "\n",
    "# Combine authentic and tampered data\n",
    "all_files = authentic_files + tampered_files\n",
    "all_labels = authentic_labels + tampered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = np.array(all_files)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    all_files, all_labels, test_size=0.4, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.8817 - loss: 0.2666 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 999ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 946ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 957ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f5eb8053f10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Image_Forgery_Predictor_Model()\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suponiendo que tienes cargados tus datos en arreglos numpy:\n",
    "# X_test es el arreglo de imágenes procesadas y y_test es el arreglo de etiquetas correspondientes\n",
    "\n",
    "tests_number = 100\n",
    "\n",
    "tampered_test = load_images_from_directory(authentic_dir, tests_number + tampered_number, i = tampered_number)\n",
    "untampered_test = load_images_from_directory(tampered_dir, tests_number + authentic_number, i = authentic_number)\n",
    "tampered_labels = [0] * len(tampered_test)\n",
    "untampered_labels = [1] * len(untampered_test)\n",
    "\n",
    "X_test = np.array(tampered_test + untampered_test)\n",
    "y_test = np.array(tampered_labels + untampered_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "Accuracy: 0.50\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n",
      "True Label: 0, Predicted Label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 20:32:18.634994: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que tienes tus datos en X_test y y_test como arreglos de numpy\n",
    "# X_test contiene las imágenes preprocesadas\n",
    "# y_test contiene las etiquetas correspondientes (0 o 1)\n",
    "\n",
    "# Crear un Dataset a partir de los datos\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "# Función para preprocesar las imágenes si es necesario\n",
    "def preprocess_image(image, label):\n",
    "    # Aquí puedes realizar cualquier preprocesamiento adicional necesario\n",
    "    return image, label\n",
    "\n",
    "# Aplicar el preprocesamiento al Dataset\n",
    "dataset = dataset.map(preprocess_image)\n",
    "\n",
    "# Definir el tamaño del lote y mezclar el Dataset (opcional)\n",
    "batch_size = 32\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "# Crear un iterador sobre el Dataset\n",
    "iterator = iter(dataset)\n",
    "\n",
    "# Lista para almacenar las predicciones y etiquetas reales\n",
    "predictions = []\n",
    "\n",
    "# Iterar sobre el Dataset para obtener predicciones\n",
    "for batch in dataset:\n",
    "    batch_images, batch_labels = batch\n",
    "    \n",
    "    # Obtener predicciones para el lote actual\n",
    "    batch_predictions = model.predict(batch_images)\n",
    "    \n",
    "    # Iterar sobre las predicciones del lote y guardarlas junto con las etiquetas reales\n",
    "    for i in range(len(batch_predictions)):\n",
    "        input_image = batch_images[i]\n",
    "        true_label = batch_labels[i]\n",
    "        predicted_label = 1 if batch_predictions[i][0] > batch_predictions[i][1] else 0\n",
    "        \n",
    "        predictions.append((input_image, true_label, predicted_label))\n",
    "\n",
    "# Evaluar el rendimiento comparando las predicciones con las etiquetas reales\n",
    "correct_predictions = 0\n",
    "total_images = len(predictions)\n",
    "\n",
    "for input_image, true_label, predicted_label in predictions:\n",
    "    if true_label == predicted_label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / total_images\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Opcional: Imprimir algunas predicciones para verificar\n",
    "for input_image, true_label, predicted_label in predictions[:100]:  # Imprimir las primeras 10 predicciones\n",
    "    print(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
